# 番外編

## 前回使ったアニメ顔検出器の実力を自分の目で確かめる

### デスクトップ画面を対象にリアルタイム検出を行うプログラム

1. 画像や動画ファイルを入力にする
  - サンプルプログラムは多く存在する
  - 入力ファイルを用意する必要があるのがやや面倒
2. Webカメラからの入力
  - こちらもサンプルはよくある
  - 検出対象がアニメ顔なのであまり使えない
3. デスクトップ画面を入力にする
  - 今回の目的には一番最適
  - サンプルが意外とないが自作はそんなに難しくなさそう

サンプルをただ動かすだけなのも面白くないので3番に決定

### やりたいこと

1. デスクトップの画像を取り込む
2. 検出処理に適切な形式にデータ変換
3. 検出実行
4. 検出結果を出力

### デスクトップの画像を取り込む

OpenCVにはちょうど良い機能がないためPIL(Pillow)のImageGrabを利用する。

```python
    img_pil = ImageGrab.grab()    # フルスクリーン画像取り込み
```

[ImageGrab Module (OS X and Windows only) — Pillow (PIL Fork) 3.0.0 documentation](https://pillow.readthedocs.io/en/3.0.x/reference/ImageGrab.html)

お気づきの通りWindows等一部のOSでしか動作しませんが気にしない

欠点としては特定のアプリケーションのみを対象にとることができないこと。  
引数で取り込む領域の座標は指定できるため、工夫次第で実現可能…？

### 検出処理に適切な形式にデータ変換

Pillowで読み込んだ画像データはそのままではOpenCVで読み込めないため変換する。

```python
img_cv = np.array(img_pil, dtype=np.uint8) # OpenCVデータに変換
```

これでおK…と思いきや落とし穴がある。
試しに以下のコードで画像保存して表示すると…

```python
cv2.imwrite('image.jpg',img_cv)  # 画像保存
```

<img src="img_cv.png" width="500">

実はOpenCVは基本的にBGR形式でデータを扱う。  
Pillowは普通にRGB形式なので変換する必要がある。

```python
img_color = cv2.cvtColor(img_cv, cv2.COLOR_RGB2BGR) # BGR形式に変換
```

<img src="img_cv2.png" width="500">

今度こそおｋ。

ついでに前回同様グレースケール変換、ヒストグラム平均化も行う。

```python
img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)  # グレースケールに変換
img_gray = cv2.equalizeHist(img_gray)   # ヒストグラム平均化
```

ヒストグラム平均化は画像の濃淡を補正して検出の精度を上げるために行う。

[ヒストグラム平坦化](https://qiita.com/Dason08/items/1b28e24d12630182fd69)

### 検出実行

前回も説明しているため省略。  
今回は誤検出（偽陽性）を減らしたいのでminNeighborsを2から3に変えてみる。  
偽陰性が増えてしまうのは妥協。

```python
faces = cascade.detectMultiScale(img_gray,
    scaleFactor = 1.1,
    minNeighbors = 3,
    minSize = (24, 24))
```

### 検出結果を出力

画面上の検出箇所を四角で囲むのが多分一番わかりやすいが、  
良い実装方法がわからないため断念……  
（赤四角の透過画像を表示しても後ろの画面が見えなくなる）

良い方法があれば募集中…！

今回は代わりに標準出力に検出数を出しつつ、  
キャプチャ画面に検出個所を赤四角で描画して画像保存することに。

```python
if len(faces) > 0:
        for x,y,w,h in faces:   # 四角を描く
            cv2.rectangle(img_color, (x,y), (x+w,y+h), color=(0,0,255), thickness=3)

        cv2.imwrite('./desktop_image/faces' + str(index) + '.jpg',img_color)  # 画像保存
        index = index + 1

    print(len(faces), "faces HIT")
```

#### 完成品

```python
import cv2
import numpy as np
from PIL import ImageGrab
import time

cascade = cv2.CascadeClassifier('lbpcascade_animeface.xml') # 検出器のファイルを指定

index = 1

while True:
    img_pil = ImageGrab.grab()    # デスクトップ画面取り込み
    img_cv = np.array(img_pil, dtype=np.uint8) #OpenCVデータに変換
    
    # BGR変換＋グレースケール変換
    if  img_cv.ndim == 2:        # モノクロ
        img_color = img_cv
        img_gray = img_color
    elif img_cv.shape[2] == 3:  # カラー
        img_color = cv2.cvtColor(img_cv, cv2.COLOR_RGB2BGR)
        img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)
    elif img_cv.shape[2] == 4:  # 透過
        img_color = cv2.cvtColor(img_cv, cv2.COLOR_RGBA2BGRA)
        img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGRA2GRAY)

    img_gray = cv2.equalizeHist(img_gray)   # ヒストグラム平均化

    # 検出実行
    faces = cascade.detectMultiScale(img_gray,
        scaleFactor = 1.1,
        minNeighbors = 3,
        minSize = (24, 24))

    if len(faces) > 0:
        for x,y,w,h in faces:   # 四角を描く
            cv2.rectangle(img_color, (x,y), (x+w,y+h), color=(0,0,255), thickness=3)

        cv2.imwrite('./desktop_image/faces' + str(index) + '.jpg',img_color)  # 画像保存
        index = index + 1

    print(len(faces), "faces HIT")

    time.sleep(1)   # 負荷軽減のため1秒ごとに認識
```

### TODO
- 切り出し保存プログラムの改良
- OpenCVのGPU環境を再構築

### 参考リンク
[[Python][Windows] Pythonでスクリーンキャプチャを行う](https://qiita.com/koara-local/items/6a98298d793f22cf2e36)  
[Pythonで簡易デスクトップキャプチャ](https://scienceboy.jp/88io/2018/12/python-quick-capture/)  
[Python】Pillow ↔ OpenCV 変換](https://qiita.com/derodero24/items/f22c22b22451609908ee)
